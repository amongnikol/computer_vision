{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76f91597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b01038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train/_annotations.csv\")\n",
    "df_test = pd.read_csv(\"data/test/_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b43923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>egohands-public-1620914960773_png_jpg.rf.aa184...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>Rock</td>\n",
       "      <td>429</td>\n",
       "      <td>185</td>\n",
       "      <td>562</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>egohands-public-1624053434391_png_jpg.rf.aaef5...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>Paper</td>\n",
       "      <td>269</td>\n",
       "      <td>354</td>\n",
       "      <td>544</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egohands-public-1624465902684_png_jpg.rf.aaa09...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>Rock</td>\n",
       "      <td>427</td>\n",
       "      <td>332</td>\n",
       "      <td>551</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Screen-Shot-2022-02-08-at-12-59-24-PM_png.rf.a...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>Rock</td>\n",
       "      <td>80</td>\n",
       "      <td>268</td>\n",
       "      <td>145</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>egohands-public-1622127402076_png_jpg.rf.aa897...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>Rock</td>\n",
       "      <td>83</td>\n",
       "      <td>128</td>\n",
       "      <td>296</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  ...  xmax ymax\n",
       "0  egohands-public-1620914960773_png_jpg.rf.aa184...    640  ...   562  319\n",
       "1  egohands-public-1624053434391_png_jpg.rf.aaef5...    640  ...   544  443\n",
       "2  egohands-public-1624465902684_png_jpg.rf.aaa09...    640  ...   551  509\n",
       "3  Screen-Shot-2022-02-08-at-12-59-24-PM_png.rf.a...    640  ...   145  395\n",
       "4  egohands-public-1622127402076_png_jpg.rf.aa897...    640  ...   296  381\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137ee1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Rock        1924\n",
       "Paper       1349\n",
       "Scissors    1337\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ff1b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Paper       72\n",
       "Scissors    67\n",
       "Rock        65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4266e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_src, is_train = True):\n",
    "    if is_train:\n",
    "        img_src = f'data/train/{img_src}'\n",
    "    else:\n",
    "        img_src = f'data/test/{img_src}'\n",
    "\n",
    "    img = cv2.imread(img_src)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e69f332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, resize, is_train = True):\n",
    "    \n",
    "    processed_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        img_src = row['filename']\n",
    "        img_class = row['class']\n",
    "\n",
    "        img = get_img(img_src, is_train)\n",
    "\n",
    "        xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']  # Cuadrado que encierra el objeto\n",
    "\n",
    "        cropped_img = img[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        cropped_img = cropped_img.astype('float32') / 255.0\n",
    "\n",
    "        resized_img = cv2.resize(cropped_img, (resize, resize))\n",
    "\n",
    "        if len(resized_img.shape) == 3 and resized_img.shape[2] == 3:\n",
    "            resized_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        resized_img = resized_img.reshape(resize, resize, 1)\n",
    "\n",
    "        processed_data.append({\n",
    "            'cropped': cropped_img,\n",
    "            'class': img_class,\n",
    "            'original': img_src,\n",
    "            'normalized': resized_img\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53c0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed = preprocess(df_train, resize=28, is_train=True)\n",
    "df_test_processed = preprocess(df_test, resize=28, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f76362de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Paper': 0, 'Rock': 1, 'Scissors': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Siapkan fitur dan label\n",
    "X_train = np.array([x for x in df_train_processed['normalized']])\n",
    "X_test = np.array([x for x in df_test_processed['normalized']])\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train_processed['class'])\n",
    "y_test = le.transform(df_test_processed['class'])\n",
    "\n",
    "# Lihat label mapping\n",
    "print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acd77053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               51328     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,659\n",
      "Trainable params: 56,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "142/145 [============================>.] - ETA: 0s - loss: 0.9826 - accuracy: 0.5271\n",
      "Epoch 1: val_loss improved from inf to 1.01680, saving model to models\\best_model_CNN.h5\n",
      "145/145 [==============================] - 4s 11ms/step - loss: 0.9806 - accuracy: 0.5289 - val_loss: 1.0168 - val_accuracy: 0.5049\n",
      "Epoch 2/100\n",
      "138/145 [===========================>..] - ETA: 0s - loss: 0.7888 - accuracy: 0.6599\n",
      "Epoch 2: val_loss improved from 1.01680 to 0.74054, saving model to models\\best_model_CNN.h5\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.7879 - accuracy: 0.6597 - val_loss: 0.7405 - val_accuracy: 0.6618\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.7202\n",
      "Epoch 3: val_loss did not improve from 0.74054\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.6621 - accuracy: 0.7202 - val_loss: 0.8296 - val_accuracy: 0.5882\n",
      "Epoch 4/100\n",
      "141/145 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7617\n",
      "Epoch 4: val_loss did not improve from 0.74054\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5833 - accuracy: 0.7618 - val_loss: 0.8774 - val_accuracy: 0.6225\n",
      "Epoch 5/100\n",
      "141/145 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.7850\n",
      "Epoch 5: val_loss improved from 0.74054 to 0.57525, saving model to models\\best_model_CNN.h5\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5317 - accuracy: 0.7844 - val_loss: 0.5752 - val_accuracy: 0.7843\n",
      "Epoch 6/100\n",
      "139/145 [===========================>..] - ETA: 0s - loss: 0.4761 - accuracy: 0.8078\n",
      "Epoch 6: val_loss did not improve from 0.57525\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4763 - accuracy: 0.8078 - val_loss: 0.6778 - val_accuracy: 0.6912\n",
      "Epoch 7/100\n",
      "138/145 [===========================>..] - ETA: 0s - loss: 0.4422 - accuracy: 0.8279\n",
      "Epoch 7: val_loss did not improve from 0.57525\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4400 - accuracy: 0.8289 - val_loss: 0.7652 - val_accuracy: 0.7157\n",
      "Epoch 8/100\n",
      "144/145 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8481\n",
      "Epoch 8: val_loss did not improve from 0.57525\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4010 - accuracy: 0.8479 - val_loss: 0.6006 - val_accuracy: 0.7696\n",
      "Epoch 9/100\n",
      "140/145 [===========================>..] - ETA: 0s - loss: 0.3578 - accuracy: 0.8632\n",
      "Epoch 9: val_loss did not improve from 0.57525\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.3587 - accuracy: 0.8633 - val_loss: 0.5873 - val_accuracy: 0.7843\n",
      "Epoch 10/100\n",
      "139/145 [===========================>..] - ETA: 0s - loss: 0.3266 - accuracy: 0.8779\n",
      "Epoch 10: val_loss did not improve from 0.57525\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.3285 - accuracy: 0.8764 - val_loss: 0.6720 - val_accuracy: 0.7696\n",
      "Epoch 11/100\n",
      "143/145 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8881\n",
      "Epoch 11: val_loss improved from 0.57525 to 0.54299, saving model to models\\best_model_CNN.h5\n",
      "145/145 [==============================] - 2s 11ms/step - loss: 0.2998 - accuracy: 0.8883 - val_loss: 0.5430 - val_accuracy: 0.8235\n",
      "Epoch 12/100\n",
      "142/145 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9062\n",
      "Epoch 12: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2701 - accuracy: 0.9067 - val_loss: 0.6222 - val_accuracy: 0.7941\n",
      "Epoch 13/100\n",
      "144/145 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9089\n",
      "Epoch 13: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2479 - accuracy: 0.9089 - val_loss: 0.6321 - val_accuracy: 0.8186\n",
      "Epoch 14/100\n",
      "141/145 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9249\n",
      "Epoch 14: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.2232 - accuracy: 0.9245 - val_loss: 0.5825 - val_accuracy: 0.8382\n",
      "Epoch 15/100\n",
      "142/145 [============================>.] - ETA: 0s - loss: 0.2020 - accuracy: 0.9296\n",
      "Epoch 15: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2022 - accuracy: 0.9295 - val_loss: 0.6055 - val_accuracy: 0.8431\n",
      "Epoch 16/100\n",
      "143/145 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9388\n",
      "Epoch 16: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9386 - val_loss: 0.6375 - val_accuracy: 0.8235\n",
      "Epoch 17/100\n",
      "141/145 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9464\n",
      "Epoch 17: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.1690 - accuracy: 0.9462 - val_loss: 0.6792 - val_accuracy: 0.8088\n",
      "Epoch 18/100\n",
      "138/145 [===========================>..] - ETA: 0s - loss: 0.1446 - accuracy: 0.9538\n",
      "Epoch 18: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9534 - val_loss: 0.6462 - val_accuracy: 0.8382\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9564\n",
      "Epoch 19: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1345 - accuracy: 0.9564 - val_loss: 0.6966 - val_accuracy: 0.8039\n",
      "Epoch 20/100\n",
      "143/145 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9580\n",
      "Epoch 20: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.1286 - accuracy: 0.9581 - val_loss: 0.7436 - val_accuracy: 0.8137\n",
      "Epoch 21/100\n",
      "140/145 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.9674\n",
      "Epoch 21: val_loss did not improve from 0.54299\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.1068 - accuracy: 0.9677 - val_loss: 0.7397 - val_accuracy: 0.8235\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callback ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='models/best_model_CNN.h5',         \n",
    "    monitor='val_loss',               \n",
    "    save_best_only=True,             \n",
    "    mode='min',                      \n",
    "    verbose=1                       \n",
    ")\n",
    "\n",
    "# Callback EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  \n",
    "    restore_best_weights=True\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
